import asyncio
import pandas as pd
import time
from scripts import run_cabinet
from functools import partial
from datetime import datetime
from scripts.setup_logger import make_logger
from scripts.telegram_logger import send_tg_message
from scripts.upload_stocks import save_in_google_sheet
from scripts.universal_main import main

logger = make_logger(__name__, use_telegram=False)


async def get_stocks(session, name, api):
    url = "https://statistics-api.wildberries.ru/api/v1/supplier/stocks"

    headers = {"Authorization": api}
    # —Ç–µ–ª–æ –∑–∞–ø—Ä–æ—Å–∞
    params = {
        "dateFrom": "2024-01-01"  # datetime.now().strftime('%Y-%m-%d')
    }
    try:
        async with session.get(url, headers=headers, params=params) as response:
            logger.info(f"üöÄüöÄ  –ù–∞—á–∏–Ω–∞—é –∑–∞–ø—Ä–æ—Å –û–°–¢–ê–¢–ö–û–í –∫ –∫–∞–±–∏–Ω–µ—Ç—É {name}")

            if response.status != 200:
                raise ValueError(f"‚ö†Ô∏è‚ö†Ô∏è –û—à–∏–±–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ '–û–°–¢–ê–¢–ö–û–í': {await response.text()}")

            result = await response.json()

    except Exception as e:
        logger.error(f"‚ùå‚ùå  –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–∑–æ–≤–µ: {e}")
        return pd.DataFrame()
    else:
        if not result:
            logger.error(f"‚ö†Ô∏è –ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –æ—Ç API –¥–ª—è {name}")
            return pd.DataFrame()

        data_stoks = pd.DataFrame(result)
    # 1. –°–æ–∑–¥–∞–µ–º –æ—Å–Ω–æ–≤–Ω—É—é —Ç–∞–±–ª–∏—Ü—É —Å –æ—Å—Ç–∞—Ç–∫–∞–º–∏

        data_stoks = data_stoks.rename(columns={
            'nmId': '–ê—Ä—Ç–∏–∫—É–ª WB',
            'lastChangeDate': '–°–ø—Ä–∞–≤–∫–∞',
            'brand': '–ë—Ä–µ–Ω–¥',
            'techSize': '–†–∞–∑–º–µ—Ä',
            'quantityFull': '–ò—Ç–æ–≥–æ –æ—Å—Ç–∞—Ç–∫–∏',
            'barcode': '–ë–∞—Ä–∫–æ–¥',
            'Price': '–¶–µ–Ω–∞',
            'Discount': '–°–∫–∏–¥–∫–∞',
            'supplierArticle': '–ê—Ä—Ç–∏–∫—É–ª –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞'})
        # –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Å—Ç–æ–ª–±–µ—Ü —Å–ø–∞—Ä–≤–∫–∞ –≤ –Ω—É–∂–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä 2025-01-01
        data_stoks['–°–ø—Ä–∞–≤–∫–∞'] = pd.to_datetime(
            data_stoks['–°–ø—Ä–∞–≤–∫–∞'], format='ISO8601').dt.date

        # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –≤ –ø–æ—Ä—è–¥–∫–µ —É–±—ã–≤–∞–Ω–∏—è
        df_sort = data_stoks.sort_values('–°–ø—Ä–∞–≤–∫–∞', ascending=False)

        # —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü –∏ –ø–æ–¥—Å—Ç–∞–≤—è–µ–º —Ç—É–¥–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –∞–∫—Ç—É–∞–ª—å–Ω—É—é —Ü–µ–Ω—É
        max_price = df_sort.loc[df_sort.groupby('–ê—Ä—Ç–∏–∫—É–ª WB',)[
            '–¶–µ–Ω–∞'].idxmax()]

        # —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü –∏ –ø–æ–¥—Å—Ç–∞–≤—è–µ–º —Ç—É–¥–∞ –ø–æ—Å–ª–µ–¥–Ω—é—é –∞–∫—Ç—É–∞–ª—å–Ω—É—é —Ü–µ–Ω—É —Å–∫–∏–¥–∫—É
        max_discount = df_sort.loc[df_sort.groupby('–ê—Ä—Ç–∏–∫—É–ª WB')[
            '–°–∫–∏–¥–∫–∞'].idxmax()]

        df_sort = df_sort.merge(
            max_price[[
                '–ê—Ä—Ç–∏–∫—É–ª WB', '–¶–µ–Ω–∞'
            ]].rename(columns={'–¶–µ–Ω–∞': '–ú–∞–∫—Å_—Ü–µ–Ω–∞'}),
            on='–ê—Ä—Ç–∏–∫—É–ª WB',
            how='left'

        ).merge(
            max_discount[[
                '–ê—Ä—Ç–∏–∫—É–ª WB', '–°–∫–∏–¥–∫–∞'
            ]].rename(columns={'–°–∫–∏–¥–∫–∞': '–ú–∞–∫—Å_—Å–∫–∏–¥–∫–∞'}),
            on='–ê—Ä—Ç–∏–∫—É–ª WB',
            how='left'
        )

        df_sort['–¶–µ–Ω–∞'] = df_sort['–ú–∞–∫—Å_—Ü–µ–Ω–∞']
        df_sort['–°–∫–∏–¥–∫–∞'] = df_sort['–ú–∞–∫—Å_—Å–∫–∏–¥–∫–∞']

        df_sort = df_sort.drop(['–ú–∞–∫—Å_—Ü–µ–Ω–∞', '–ú–∞–∫—Å_—Å–∫–∏–¥–∫–∞'], axis=1)

        logger.info(
            f"[92m‚úÖ –û—Å—Ç–∞—Ç–∫–∏ {name} —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã: {len(df_sort)} —Å—Ç—Ä–æ–∫")

        return df_sort


def merge_and_transform_stocks_with_idkt(stocks, IDKT, name):
    try:
        logger.info(
            "üìä –ü—Ä–∏–≤–æ–¥–∏–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö –≤ —Å—Ç–æ–ª–±—Ü–∞—Ö [–ê—Ä—Ç–∏–∫—É–ª WB, –ë–∞—Ä–∫–æ–¥, –†–∞–∑–º–µ—Ä, ID KT]...")

        type_map = {
            '–ê—Ä—Ç–∏–∫—É–ª WB': int,
            '–ë–∞—Ä–∫–æ–¥': str,
            '–†–∞–∑–º–µ—Ä': str
        }
        for df in [stocks, IDKT]:
            for col, dtype in type_map.items():
                df[col] = df[col].astype(dtype)

        IDKT['ID KT'] = IDKT['ID KT'].astype(int)

        logger.info("‚úÖ –¢–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–æ –ø—Ä–∏–≤–µ–¥–µ–Ω—ã!")
    except Exception as e:
        logger.error(
            f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–∏–≤–µ—Å—Ç–∏ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö: {e}")
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –¥–≤–µ —Ç–∞–±–ª–∏—Ü—ã –æ—Å—Ç–∞—Ç–∫–∏ —Ü–µ–ø–ª—è–µ–º –∫ idkt
    try:
        logger.info("üîó –í—ã–ø–æ–ª–Ω—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü (merge)...")

        result = pd.merge(
            IDKT,
            stocks,
            on=['–ê—Ä—Ç–∏–∫—É–ª WB', '–ë–∞—Ä–∫–æ–¥'],
            how='outer',
            indicator=True,
            suffixes=('_IDKT', '_stocks')
        )
        logger.info("‚úÖ –û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")

    except Exception as e:
        logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—ä–µ–¥–∏–Ω–∏—Ç—å —Ç–∞–±–ª–∏—Ü—ã: {e}")

    try:
        logger.info("üßπ –ù–∞—á–∏–Ω–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –æ—á–∏—Å—Ç–∫—É –∏ –æ–±—Ä–∞–±–æ—Ç–∫—É –¥–∞–Ω–Ω—ã—Ö...")
        # –£–¥–∞–ª—è–µ–º –Ω–µ –Ω—É–∂–Ω—ã–µ —Å—Ç–æ–ª–±—Ü—ã
        result = result.drop(columns=[col for col in result.columns if col.endswith('_stocks')]+['–°–ø—Ä–∞–≤–∫–∞', 'warehouseName',
                                                                                                 'quantity', 'inWayToClient', 'inWayFromClient', 'category', 'subject', 'isRealization', 'SCCode', 'isSupply'])

        # —É–¥–∞–ª—è–µ–º —Å—É—Ñ—Ñ–∏–∫—Å—ã _IDKT —É —Å—Ç–æ–ª–±—Ü–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –æ—Å—Ç–∞–ª–∏—Å—å
        result.columns = [
            col.replace('_IDKT', '') for col in result.columns
        ]

        # –≤—ã–±–∏—Ä–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã
        num_col = ['–¶–µ–Ω–∞', '–°–∫–∏–¥–∫–∞',
                   '–ò—Ç–æ–≥–æ –æ—Å—Ç–∞—Ç–∫–∏', '–®–∏—Ä–∏–Ω–∞', '–í—ã—Å–æ—Ç–∞', '–î–ª–∏–Ω–∞']
        string_cols = ['–ë—Ä–µ–Ω–¥', '–†–∞–∑–º–µ—Ä', '–ö–∞—Ç–µ–≥–æ—Ä–∏—è', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ',
                       ]

        # –ó–∞–ø–æ–ª–Ω—è–µ–º NAN –≤ –¶–µ–Ω–∞ –∏ –°–∫–∏–¥–∫–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–º–∏ –∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ –∑–Ω–∞—á –¥–ª—è –∞—Ä—Ç–∏–∫—É–ª–∞
        result[['–¶–µ–Ω–∞', '–°–∫–∏–¥–∫–∞']] = result.groupby(
            '–ê—Ä—Ç–∏–∫—É–ª WB')[['–¶–µ–Ω–∞', '–°–∫–∏–¥–∫–∞']].ffill()
        # –∑–∞–ø–æ–ª–Ω—è–µ–º –ø—É—Å—Ç–æ—Ç—ã –Ω—É–∂–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        result[num_col] = result[num_col].fillna(0)
        result[string_cols] = result[string_cols].fillna('-')

        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ —Å—Ç—Ä–æ–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å –≤ —Ç–∞–±–ª–∏—Ü–µ stocks –æ—Å—Ç–∞—Ç–∫–∏
        right_only_rows = result[result['_merge'] == 'right_only']

        # –≤ –æ—Å–Ω–æ–Ω–æ–º –¥—Ñ —É–¥–∞–ª—è–µ–º —Å—Ç—Ä–æ–∫–∏ –∫–æ—Ç–æ—Ä—ã–µ –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ –≤ –ø—Ä–∞–≤–æ–π —Ç–∞–±–ª–∏—Ü–µ, –æ–Ω–∏ –∫–æ—Å—è—á–Ω—ã–µ
        result = result[result['_merge'] != 'right_only']

        # —É–¥–∞–ª—è–µ–º —Å—Ç–æ–ª–±–µ—Ü _merge
        result = result.drop(columns='_merge')

        # –≥—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Å—Ç–æ–ª–±—Ü—É –∏—Ç–æ–≥–æ –æ—Å—Ç–∞—Ç–∫–∏
        result = result.groupby([
            col for col in result.columns if col != '–ò—Ç–æ–≥–æ –æ—Å—Ç–∞—Ç–∫–∏'
        ])['–ò—Ç–æ–≥–æ –æ—Å—Ç–∞—Ç–∫–∏'].sum().reset_index()

        # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π —Å—Ç–æ–ª–±–µ—Ü –¶–µ–Ω–∞ –¥–æ –°–ü–ü
        result['–¶–µ–Ω–∞ –¥–æ –°–ü–ü'] = result['–¶–µ–Ω–∞'] * \
            (1 - result['–°–∫–∏–¥–∫–∞']/100)

        # –¥—Ñ —Å –∞—Ä—Ç–∏–∫—É–ª–æ–º –∏ –±–∞—Ä–∫–æ–¥–æ–º
        barcode_nmid = result.filter([
            '–ê—Ä—Ç–∏–∫—É–ª WB', '–ë–∞—Ä–∫–æ–¥', '–†–∞–∑–º–µ—Ä'
        ])

        result = result.drop(columns=[
            '–ë–∞—Ä–∫–æ–¥', '–†–∞–∑–º–µ—Ä'
        ])

        result[['–¶–µ–Ω–∞', '–°–∫–∏–¥–∫–∞', '–¶–µ–Ω–∞ –¥–æ –°–ü–ü']] = result.groupby(
            '–ê—Ä—Ç–∏–∫—É–ª WB')[['–¶–µ–Ω–∞', '–°–∫–∏–¥–∫–∞', '–¶–µ–Ω–∞ –¥–æ –°–ü–ü']].transform('first')

        # –≥—Ä—É–ø–ø–∏—Ä–æ–≤–∫–∞ –ø–æ—Å–ª–µ —É–¥–∞–ª–µ–Ω–∏—è –ø–æ —Å—É–º–º–µ –æ—Å—Ç–∞—Ç–∫–æ–≤
        result = result.groupby([
            col for col in result.columns if col != '–ò—Ç–æ–≥–æ –æ—Å—Ç–∞—Ç–∫–∏'
        ])['–ò—Ç–æ–≥–æ –æ—Å—Ç–∞—Ç–∫–∏'].sum().reset_index()

        new_order = [
            '–ê—Ä—Ç–∏–∫—É–ª WB', 'ID KT', '–ê—Ä—Ç–∏–∫—É–ª –ø–æ—Å—Ç–∞–≤—â–∏–∫–∞', '–ë—Ä–µ–Ω–¥', '–ù–∞–∏–º–µ–Ω–æ–≤–∞–Ω–∏–µ', '–ö–∞—Ç–µ–≥–æ—Ä–∏—è',
            '–ò—Ç–æ–≥–æ –æ—Å—Ç–∞—Ç–∫–∏', '–¶–µ–Ω–∞', '–°–∫–∏–¥–∫–∞', '–¶–µ–Ω–∞ –¥–æ –°–ü–ü', '–§–æ—Ç–æ', '–®–∏—Ä–∏–Ω–∞', '–í—ã—Å–æ—Ç–∞', '–î–ª–∏–Ω–∞'
        ]

        # –ø—Ä–∏–º–µ–Ω—è–µ–º –Ω–æ–≤–æ–µ —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω–∏–µ
        result = result[new_order]

        result = result.sort_values('–ò—Ç–æ–≥–æ –æ—Å—Ç–∞—Ç–∫–∏', ascending=False)
        result['–ö–∞–±–∏–Ω–µ—Ç'] = name

        if len(right_only_rows) > 0:
            logger.warning(
                f"–∫–æ—Å—è—á–Ω–∞—è –∫–∞—Ä—Ç–æ—á–∫–∞ –∫–∞–±–∏–Ω–µ—Ç–∞ {name} =  {right_only_rows.shape}\n{right_only_rows['–ê—Ä—Ç–∏–∫—É–ª WB'].to_list()}")

        else:
            logger.info(f"‚úÖ –ö–æ—Å—è—á–Ω—ã—Ö –∫–∞—Ä—Ç–æ—á–µ–∫ –≤ {name} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")

        logger.warning(
            f"üü¢ –ï—Å—Ç—å –ª–∏ –¥—É–±–ª–∏–∫–∞—Ç—ã –≤ {name}?: {result.duplicated().any()}\n"
            f"üì¶ –ö–æ–ª–æ–Ω–∫–∏ barcode_nmid: {barcode_nmid.columns.tolist()}"
        )

    except Exception as e:
        logger.error(
            f"‚ùå –û—à–∏–±–∫–∞ –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")

    return result, barcode_nmid


if __name__ == '__main__':
    send_tg_message(
        f"üèÅ –°–∫—Ä–∏–ø—Ç –∑–∞–ø—É—â–µ–Ω 'get_stocks': {datetime.now():%Y-%m-%d %H:%M:%S}")

    begin = time.time()

    result_data = asyncio.run(main(
        run_funck=partial(run_cabinet.execute_run_cabinet,
                          func_name='get_stocks'),
        postprocess_func=merge_and_transform_stocks_with_idkt,
        cache_name="test_cache.pkl"
    ))

    save_in_google_sheet(result_data)
    end = time.time()

    print(f"üòé –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {(end-begin)/60:,.2f}")
